
# 1. Why do you think companies analyze large volumes of data?
# Companies analyze large volumes of data to make informed decisions, understand customer behavior,
# improve operational efficiency, identify trends, reduce risks, and gain a competitive advantage.

# 2. If analyzing and sorting large data manually in Excel is difficult, how do you think Python can help solve this problem?
# Python can automate data processing using libraries like pandas and numpy, handle very large datasets efficiently,
# perform complex calculations quickly, and reduce human error through reusable scripts.

# 3. Imagine you work at a sales company that receives data about 10,000 customer transactions daily.
# How would you analyze this data?
# I would store the data in a database or structured files, clean and preprocess it using Python,
# calculate key metrics such as total sales, average order value, and trends,
# and visualize results using charts or dashboards.

# 4. In your opinion, what tasks can Python be useful for in BI processes?
# Python is useful for data collection, data cleaning, transformation, analysis,
# statistical modeling, automation, visualization, and report generation in BI processes.

# 5. If you wanted to compare a company's profit year by year, how could this be done using Python?
# Profit data could be loaded into Python, grouped by year using pandas,
# summarized using aggregation functions, and compared using tables or visualizations like line charts.

# 6. If you don't know Python, what difficulties might you face when working with large datasets?
# Without Python, tasks may become slow and manual, large datasets may exceed Excel limits,
# automation would be difficult, and performing advanced analysis or reproducible workflows
# would be much harder.

